== Scaling
:source-highlighter: coderay

At the end of this chapter you will be able to:

* Configure the scale to zero time period
* Configure auto scaling
* Understanding types of autoscaling strategies
* How to enable concurrency based auto scaling based concurrency
* How to prevent minimum number of pods for a service i.e. no scale down to zero beyond this number of pods

[#scaling-prerequisite]
=== Prerequisite 
include::./_prereq-cli.adoc[leveloffset=+1]

[#scaling-containers]
=== Build Containers
include::./_buildcontainers.adoc[leveloffset=+1]

[#scaling-deploy-service]
=== Deploy Service

The following snippet shows how a Knative service YAML will look like:

[source,yaml,linenums]
----
apiVersion: serving.knative.dev/v1alpha1
kind: Service
metadata:
  name: greeter
spec:
  runLatest: #<1>
    configuration:
      revisionTemplate:
        spec:
          container:
            image: dev.local/rhdevelopers/greeter:0.0.1 #<2>
----

[.text-center]
**service.yaml**

<1> Makes Knative to always run the latest revision of the deployment
<2> It is very important that the image is a fully qualified name docker image name with tag. For more details on this <<faq-q2,Question 2 of FAQ>>

The service could be deployed using the command:
[source,bash]
----
cd $TUTORIAL_HOME/01-basics/knative
----

[source,bash]
----
oc apply -n knativetutorial -f service.yaml
----

[.text-center]
**(OR)**

[source,bash]
----
kubectl apply -n knativetutorial -f service.yaml
----

After successful deployment of the service we should see a Kubernetes deployment called `greeter-00001-deployment` available in the OpenShift dashboard:

image::greeter-00001.png[Greeter Service]

[#scaling-invoke-service]
=== Invoke Service

include::./_invokeservice.adoc[leveloffset=+1,tags=*]

The last curl command should return a response like **Hi greeter => greeter-00001-deployment-5d696cc6c8-m65s5: 1**

Check <<basics-see-what-you-have-deployed,deployed Knative resources>> tfor more details of what Knative objects and resources have been created with the above service deployment.

==== Configure scale to zero 

Assuming that <<scaling-deploy-service, Greeter service>> has been deployed, if the service has been terminated, the let us <<scaling-invoke-service, invoke the service>> to make service available for request.

[#scale-to-zero-formulae]
===== Calculating scale to zero time period

Knative autoscaler uses the config map **config-autoscaler** of **knative-serving** namespace for autoscaling related properties.  The value of the attribute `stable-window` and `scale-to-zero-grace-period` decides how long Knative autoscaler will wait before terminating the inactive revision pod.  

[source,bash]
----
stableWindow=`oc -n knative-serving get configmaps config-autoscaler -o yaml |
 yq r - data.stable-window`
scaleToZeroGracePeriod=`oc -n knative-serving get configmaps config-autoscaler -o yaml |
 yq r - data.scale-to-zero-grace-period`
----

[.text-center]
**(OR)**

[source,bash]
----
stableWindow=`kubectl -n knative-serving get configmaps config-autoscaler -o yaml |
 yq r - data.stable-window`
scaleToZeroGracePeriod=`kubectl -n knative-serving get configmaps config-autoscaler -o yaml |
 yq r - data.scale-to-zero-grace-period`
----

[.text-center]
`termination period time in seconds = stableWindow + scaleToZeroGracePeriod`

[IMPORTANT]
====
* scale-to-zero-grace-period is dynamic parameter i.e. the value is immediately effected after updating the config map
* the minimum value that can be set for `scale-to-zero-grace-period` is 30 seconds
====

==== Observing default scale down 

You can open a new terminal and run the command `watch 'oc get pods -n knativetutorial'` to view the scale up and scale down to zero.

Checking default values
[source,bash]
----
# should return 60s
echo $stableWindow 
# should return 30s
echo $scaleToZeroGracePeriod 
----

By default the **scale-to-zero-grace-period** is `30s`, and the **stable-window** is `60s`, firing the request to the greeter service will bring up the pod (if its already terminated) to serve the request. Leaving it without any further requests, it will automatically scale to zero `1 min 30 secs`(<<scale-to-zero-formulae,Compute scale to zero grace period>>)..

==== Update scale down to 1 minute

Let us now update **scale-to-zero-grace-period** to `1m` and leave the **stable-window** to default `60s`.

[source,bash]
----
cd $TUTORIAL_HOME/03-scaling/knative
----

[source,bash]
----
oc -n knative-serving get cm config-autoscaler -o yaml | yq w - -s configure-scaling-to-1m.yaml | oc apply -f -
----

[.text-center]
**(OR)**

[source,bash]
----
kubectl -n knative-serving get cm config-autoscaler -o yaml | yq w - -s configure-scaling-to-1m.yaml | kubectl apply -f -
----

Verifying the `scale-to-zero-grace-period` value, which should return `1m`: 

[source,bash]
----
oc -n knative-serving get configmap config-autoscaler -o yaml \
  | yq r - data.scale-to-zero-grace-period
----

[.text-center]
**(OR)**

[source,bash]
----
kubectl -n knative-serving get configmap config-autoscaler -o yaml \
 | yq r - data.scale-to-zero-grace-period
----

Now <<scaling-invoke-service,firing the request>> to the greeter service will bring up the pod to serve the request.Leaving it without any further requests, it will automatically scale to zero `2 mins`(<<scale-to-zero-formulae,Compute scale to zero grace period>>)

==== Update scale down to 2 minute

Let us now update **scale-to-zero-grace-period** to `2m` and leave the **stable-window** to default `60s`.

[source,bash]
----
oc -n knative-serving get cm config-autoscaler -o yaml | yq w - -s configure-scaling-to-2m.yaml | oc apply -f -
----

[.text-center]
**(OR)**

[source,bash]
----
kubectl -n knative-serving get cm config-autoscaler -o yaml | yq w - -s configure-scaling-to-2m.yaml | kubectl apply -f -
----

Verifying the `scale-to-zero-grace-period` value, which should return `2m`: 

[source,bash]
----
# should return 2m
oc -n knative-serving get configmap config-autoscaler -o yaml \
  | yq r - data.scale-to-zero-grace-period
----

[.text-center]
**(OR)**

[source,bash]
----

kubectl -n knative-serving get configmap config-autoscaler -o yaml \
 | yq r - data.scale-to-zero-grace-period
----

Now <<scaling-invoke-service,firing the request>> to the greeter service will bring up the pod to serve the request and if we leave the service without any further requests, it will automatically scale to zero in `3 mins`(<<scale-to-zero-formulae,Compute scale to zero grace period>>).

==== Reset to defaults

Let us revert the `scale-to-zero-grace-period` to defaults:

[source,bash]
----
oc -n knative-serving get cm config-autoscaler -o yaml | yq w - -s configure-scaling-to-30s.yaml | oc apply -f -
----

[.text-center]
**(OR)**

[source,bash]
----
kubectl -n knative-serving get cm config-autoscaler -o yaml | yq w - -s configure-scaling-to-30s.yaml | kubectl apply -f -
----

Verifying the `scale-to-zero-grace-period` value, which should return `30s`: 

[source,bash]
----
# should return 2m
oc -n knative-serving get configmap config-autoscaler -o yaml \
  | yq r - data.scale-to-zero-grace-period
----

[.text-center]
**(OR)**

[source,bash]
----

kubectl -n knative-serving get configmap config-autoscaler -o yaml \
 | yq r - data.scale-to-zero-grace-period
----

For the sake of clarity and better understanding <<scaling-cleanup,clean up>> the deployed knative service before going to next section.

[#scaling-auto-scaling]
=== Auto Scaling

By default Knative Serving allows 100 concurrency pods, you can view the setting `container-concurrency-target-default` in the configmap **config-autoscaler ** of **knative-serving** namespace.

For this exercise let us make our service handle only **10** concurrent requests,this will make the Knative-Serving to scale the pods to handle the requests more than 10 requests

[#scaling-concurrency-10]
==== Service with concurrency of 10 requests

[source,yaml,linenums]
----
apiVersion: serving.knative.dev/v1alpha1
kind: Service
metadata:
  name: greeter
spec:
  runLatest:
    configuration:
      revisionTemplate:
        metadata:
          annotations:
            autoscaling.knative.dev/target: "10" #<1>
        spec:
          container:
            image: dev.local/rhdevelopers/greeter:0.0.1
            livenessProbe:
              httpGet:
                path: /healthz
            readinessProbe:
              httpGet:
                path: /healthz
----
[.text-center]
**service-10.yaml**

<1> Will allow each service pod to handle max of 10 in-flight requests per pod before automatically scaling to new pod(s)

[#scaling-deploy-service]
==== Deploy service 

[source,bash]
----
oc apply -n knativetutorial -f service-10.yaml
----

[.text-center]
**(OR)**

[source,bash]
----
kubectl apply -n knativetutorial -f service-10.yaml
----

[#scaling-invoke-service]
==== Invoke Service 

include::./_invokeservice.adoc[leveloffset=+1,tag=env]

Open a new terminal and run the following command:

[source,bash]
----
watch oc get pods -n knativetutorial
----

[.text-center]
**(OR)**

[source,bash]
----
watch kubectl get pods -n knativetutorial
----

[#scaling-load-service]
==== Load the service

We will now send some load to the greeter service.  The command below sends 50 concurrent requests (`-c 50`) for next 10s (`-z 10s`) with no connection timeout(`-t 0`)

[source,bash]
----
hey -z 10s -c 50 -t 0 \
  -host "greeter.knativetutorial.example.com" \
  "http://${IP_ADDRESS}"
----

After successful run the load test, you will notice the number of greeter service pods would have automatically scaled to 5, you can also view the same via OpenShift dashboard as shown below:

image::greeter-00001-scaled.png[Greeter Service]

The autoscale pods is computed using the formula:

[.text-center]
[source,bash]
----
totalPodsToScale = total number of inflight requests / average concurrency target
----

With this current setting of **average concurrency target=10**(`autoscaling.knative.dev/target: "10"`) and **total number of inflight requests=50** , you will see Knative automatically scales the greeter services to  `**50/10 = 5 pods**`.

For more clarity and understanding let us <<scaling-cleanup,clean up>> existing deployments  before proceeding to next section.

[#scaling-min-scale]
=== Minimum Scale

At times you might need that you always need to have `n` number of pods running e.g. cases where you want to handle sudden spike in requests, with Knative auto scaling we can do that with via `minScale` annotation.

[#scaling-deploy-service-minscale]
==== Deploy service 

[source,yaml,linenums]
----
apiVersion: serving.knative.dev/v1alpha1
kind: Service
metadata:
  name: greeter
spec:
  runLatest:
    configuration:
      revisionTemplate:
        metadata:
          annotations:
            autoscaling.knative.dev/target: "10"  #<1>
            autoscaling.knative.dev/minScale: "2" #<2>
        spec:
          container:
            image: dev.local/rhdevelopers/greeter:0.0.1
            livenessProbe:
              httpGet:
                path: /healthz
            readinessProbe:
              httpGet:
                path: /healthz
----
[.text-center]
**service-min-scale.yaml**

<1> Will allow each service pod to handle max of 10 in-flight requests per pod before automatically scaling to new pod(s)
<2> Every new deployment of this service will minimum have two pods

[source,bash]
----
oc apply -n knativetutorial -f service-min-scale.yaml
----

[.text-center]
**(OR)**

[source,bash]
----
kubectl apply -n knativetutorial -f service-min-scale.yaml
----

After successful deployment of the service we should see a Kubernetes deployment called `greeter-00001-deployment` with **two** pods readily available.

image::greeter-00001-minscale.png[Greeter Service]

[.text-center]
**OpenShift Dashboard Knative Tutorial project**

Open a new terminal and run the following command :

[source,bash]
----
watch oc get pods -n knativetutorial
----

[.text-center]
**(OR)**

[source,bash]
----
watch kubectl get pods -n knativetutorial
----

Let us <<scaling-load-service,send some load to the service>> to trigger autoscaling.

When all requests are done and if you are beyond the `scale-to-zero-grace-period`, you will notice that Knative has terminated only 3 out 5 pods, this is because we have configured Knative to always run two pods via the annotation `autoscaling.knative.dev/minScale: "2"` 

[#scaling-cleanup]
=== Cleanup
[source,bash]
----
oc -n knativetutorial delete services.serving.knative.dev greeter
----

[.text-center]
**(OR)**

[source,bash]
----
kubectl -n knativetutorial delete services.serving.knative.dev greeter
----
